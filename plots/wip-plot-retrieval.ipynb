{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from _data import (\n",
    "    get_per_study_data,\n",
    "    get_split_features,\n",
    "    get_split_samples,\n",
    "    DEFAULT_PATIENT_ID_COL,\n",
    "    DEFAULT_STUDY_ID_COL,\n",
    "    DEFAULT_DICOM_ID_COL,\n",
    "    DEFAULT_SPLIT_COL,\n",
    "    DEFAULT_VIEW_COL,\n",
    "    DEFAULT_LABELS,\n",
    "    DEFAULT_VIEW_ORDER,\n",
    "    DEFAULT_FINDINGS_COL,\n",
    "    DEFAULT_IMPRESSION_COL,\n",
    "    DEFAULT_IMG_PROJ_KEY,\n",
    ")\n",
    "from _prompt import prepare_prompt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import trange\n",
    "import _prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieved_idxs(section_type):\n",
    "    _prompt.cached = None\n",
    "    split_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\"\n",
    "    metadata_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-metadata.csv\"\n",
    "    true_label_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-chexpert.csv\"\n",
    "    predicted_label_csv = \"/opt/gpudata/rrg-data-2/image-labels/pred_pr.csv\"\n",
    "    report_csv = \"/opt/gpudata/mimic-cxr/mimic_cxr_sectioned.csv\"\n",
    "    add_other_label = True\n",
    "    feature_h5 = \"/opt/gpudata/rrg-data-2/biovilt-features.h5\"\n",
    "    prompt_yaml = \"prompts.yaml\"\n",
    "    labels = DEFAULT_LABELS.copy()\n",
    "    prompt_type = \"simple\"\n",
    "\n",
    "    # TODO parameterize hardcoded split remapping\n",
    "    split_remap = {\n",
    "        \"train\": \"retrieval\",\n",
    "        \"validate\": \"retrieval\",\n",
    "        \"test\": \"inference\",\n",
    "    }\n",
    "\n",
    "    # Load and merge data relative to true labels\n",
    "    retrieval_df = get_per_study_data(\n",
    "        split_csv=split_csv,\n",
    "        metadata_csv=metadata_csv,\n",
    "        label_csv=true_label_csv,\n",
    "        report_csv=report_csv,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "        view_col=DEFAULT_VIEW_COL,\n",
    "        labels=labels,\n",
    "        view_order=DEFAULT_VIEW_ORDER,\n",
    "        report_cols=[DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL],\n",
    "        split_remap=split_remap,\n",
    "    )\n",
    "\n",
    "    # Load and merge data relative to predicted labels if provided\n",
    "    inference_df = get_per_study_data(\n",
    "        split_csv=split_csv,\n",
    "        metadata_csv=metadata_csv,\n",
    "        label_csv=predicted_label_csv or true_label_csv,\n",
    "        report_csv=report_csv,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "        view_col=DEFAULT_VIEW_COL,\n",
    "        labels=labels,\n",
    "        view_order=DEFAULT_VIEW_ORDER,\n",
    "        report_cols=[DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL],\n",
    "        split_remap=split_remap,\n",
    "    )\n",
    "\n",
    "    # Check that true and predicted labels result in same merged dataframes\n",
    "    cols = [DEFAULT_PATIENT_ID_COL, DEFAULT_STUDY_ID_COL, DEFAULT_DICOM_ID_COL, DEFAULT_SPLIT_COL, DEFAULT_VIEW_COL]\n",
    "    assert retrieval_df[cols].equals(inference_df[cols])\n",
    "\n",
    "    # Filter dataset to only those with given section type\n",
    "    if section_type == \"findings\":\n",
    "        report_cols = [DEFAULT_FINDINGS_COL]\n",
    "    elif section_type == \"impression\":\n",
    "        report_cols = [DEFAULT_IMPRESSION_COL]\n",
    "    elif section_type in [\"both\", \"findings-intersect\", \"impression-intersect\"]:\n",
    "        report_cols = [DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown section type: {section_type}\")\n",
    "\n",
    "    mask = retrieval_df[report_cols].notna().all(axis=1)\n",
    "    retrieval_df = retrieval_df[mask].reset_index(drop=True).copy()\n",
    "    inference_df = inference_df[mask].reset_index(drop=True).copy()\n",
    "\n",
    "    # Add implicit \"other\" label\n",
    "    if add_other_label:\n",
    "        # TODO does \"other\" definition depend on prompt type?\n",
    "        retrieval_df[\"Other\"] = (retrieval_df[labels] != 1).all(axis=1).astype(int)\n",
    "        inference_df[\"Other\"] = (inference_df[labels] != 1).all(axis=1).astype(int)\n",
    "        labels += [\"Other\"]\n",
    "\n",
    "    # Prepare per-split projected embeddings\n",
    "    features = get_split_features(\n",
    "        feature_h5=feature_h5,\n",
    "        feature_key=DEFAULT_IMG_PROJ_KEY,\n",
    "        sample_df=retrieval_df,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )\n",
    "    retrieval_features = features[\"retrieval\"]\n",
    "    inference_features = features[\"inference\"]\n",
    "\n",
    "    # Prepare per-split metadata, labels, and reports\n",
    "    retrieval_samples = get_split_samples(\n",
    "        sample_df=retrieval_df,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )[\"retrieval\"]\n",
    "    inference_samples = get_split_samples(\n",
    "        sample_df=inference_df,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )[\"inference\"]\n",
    "\n",
    "    # Prepare prompt templates\n",
    "    with open(prompt_yaml) as f:\n",
    "        prompt_templates = yaml.safe_load(f)\n",
    "\n",
    "    # Compute similarity between inference and retrieval samples\n",
    "    similarity = cosine_similarity(inference_features, retrieval_features)\n",
    "\n",
    "    # Generate reports\n",
    "    N = len(inference_samples)\n",
    "\n",
    "    exact_filter_retrieved_idxs = []\n",
    "    for i in trange(N):\n",
    "        prompt, target_report, retrieved_studies, idxs = prepare_prompt(\n",
    "            retrieval_samples=retrieval_samples,\n",
    "            target_sample=inference_samples.iloc[i],\n",
    "            target_similarity=similarity[i],\n",
    "            k=5,\n",
    "            prompt_templates=prompt_templates,\n",
    "            filter_type=\"exact\",\n",
    "            prompt_type=prompt_type,\n",
    "            section_type=section_type,\n",
    "            labels=labels,\n",
    "            findings_col=DEFAULT_FINDINGS_COL,\n",
    "            impression_col=DEFAULT_IMPRESSION_COL,\n",
    "            study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "            return_relative_idxs=True,\n",
    "        )\n",
    "        exact_filter_retrieved_idxs.append(idxs)\n",
    "    \n",
    "    partial_filter_retrieved_idxs = []\n",
    "    for i in trange(N):\n",
    "        prompt, target_report, retrieved_studies, idxs = prepare_prompt(\n",
    "            retrieval_samples=retrieval_samples,\n",
    "            target_sample=inference_samples.iloc[i],\n",
    "            target_similarity=similarity[i],\n",
    "            k=5,\n",
    "            prompt_templates=prompt_templates,\n",
    "            filter_type=\"partial\",\n",
    "            prompt_type=prompt_type,\n",
    "            section_type=section_type,\n",
    "            labels=labels,\n",
    "            findings_col=DEFAULT_FINDINGS_COL,\n",
    "            impression_col=DEFAULT_IMPRESSION_COL,\n",
    "            study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "            return_relative_idxs=True,\n",
    "        )\n",
    "        partial_filter_retrieved_idxs.append(idxs)\n",
    "    \n",
    "    return exact_filter_retrieved_idxs, partial_filter_retrieved_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_exact, findings_partial = get_retrieved_idxs(\"findings\")\n",
    "impression_exact, impression_partial = get_retrieved_idxs(\"impression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "cmap = sns.color_palette(palette=\"Set3\")\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(6, 3))\n",
    "\n",
    "# gs = GridSpec(2, 3, figure=fig, width_ratios=[5, 5, 1])\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# ax3 = fig.add_subplot(gs[1, 0])\n",
    "# ax4 = fig.add_subplot(gs[1, 1])\n",
    "# ax_legend = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "bins = list(range(27))\n",
    "bins[-1] = 1000000\n",
    "\n",
    "sns.histplot([x - 1 for xs in findings_exact for x in xs], bins=bins, ax=ax1, color=cmap[4], linewidth=1, zorder=10, alpha=1, edgecolor=\"grey\")\n",
    "sns.histplot([x - 1 for xs in findings_partial for x in xs], bins=bins, ax=ax2, color=cmap[1], linewidth=1, zorder=10, alpha=1, edgecolor=\"grey\")\n",
    "sns.histplot([x - 1 for xs in impression_exact for x in xs], bins=bins, ax=ax3, color=cmap[4], linewidth=1, zorder=10, alpha=1, edgecolor=\"grey\")\n",
    "sns.histplot([x - 1 for xs in impression_partial for x in xs], bins=bins, ax=ax4, color=cmap[1], linewidth=1, zorder=10, alpha=1, edgecolor=\"grey\")\n",
    "\n",
    "ax1.set_title(f\"Exact Filter, Findings, N={len(findings_exact)}\", fontsize=10)\n",
    "ax2.set_title(f\"Partial Filter, Findings, N={len(findings_exact)}\", fontsize=10)\n",
    "ax3.set_title(f\"Exact Filter, Impression, N={len(impression_exact)}\", fontsize=10)\n",
    "ax4.set_title(f\"Partial Filter, Impression, N={len(impression_exact)}\", fontsize=10)\n",
    "\n",
    "ax1.set_ylim([0, 550])\n",
    "ax2.set_ylim([0, 550])\n",
    "ax3.set_ylim([0, 550])\n",
    "ax4.set_ylim([0, 550])\n",
    "\n",
    "ax1.set_xlim([0, 26])\n",
    "ax2.set_xlim([0, 26])\n",
    "ax3.set_xlim([0, 26])\n",
    "ax4.set_xlim([0, 26])\n",
    "\n",
    "ax1.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax2.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax3.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax4.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "ax3.set_xticklabels([0, 5, 10, 15, 20, \"25+\"])\n",
    "ax4.set_xticklabels([0, 5, 10, 15, 20, \"25+\"])\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax3.set_xlabel(\"Image Similarity Rank\")\n",
    "ax4.set_xlabel(\"Image Similarity Rank\")\n",
    "\n",
    "ax2.set_ylabel(\"\")\n",
    "ax4.set_ylabel(\"\")\n",
    "\n",
    "ax1.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax2.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax3.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax4.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "\n",
    "ax1.set_yticklabels([0, 100, 200, 300, 400, 500])\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([0, 100, 200, 300, 400, 500])\n",
    "ax4.set_yticklabels([])\n",
    "\n",
    "ax1.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax2.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax3.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax4.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "\n",
    "# legend_elements = [\n",
    "#     Patch(\n",
    "#         facecolor=cmap[4],\n",
    "#         # edgecolor=\"gray\",\n",
    "#         label=\"Exact\",\n",
    "#     ),\n",
    "#     Patch(\n",
    "#         facecolor=cmap[1],\n",
    "#         # edgecolor=\"gray\",\n",
    "#         label=\"Partial\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "ax1_25n = (pd.Series([x - 1 for xs in findings_exact for x in xs]) >= 25).sum()\n",
    "ax1.text(25.6, 275, f\"{ax1_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\", fontsize=7.5)\n",
    "ax2_25n = (pd.Series([x - 1 for xs in impression_exact for x in xs]) >= 25).sum()\n",
    "ax2.text(25.6, 275, f\"{ax2_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\", fontsize=7.5)\n",
    "ax3_25n = (pd.Series([x - 1 for xs in findings_partial for x in xs]) >= 25).sum()\n",
    "ax3.text(25.6, 275, f\"{ax3_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\", fontsize=7.5)\n",
    "ax4_25n = (pd.Series([x - 1 for xs in impression_partial for x in xs]) >= 25).sum()\n",
    "ax4.text(25.6, 275, f\"{ax4_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\", fontsize=7.5)\n",
    "\n",
    "# ax_legend.legend(handles=legend_elements, loc=\"center left\", title=\"Filter\", title_fontproperties={\"weight\": \"semibold\"})\n",
    "# ax_legend.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Top 5 Filtered Image Similarity\", y=.95, fontsize=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(f\"figs-png/Filter Rank Count.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import f1chexbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\")\n",
    "generations = pd.read_csv(\"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings.csv\")\n",
    "\n",
    "cxrmate_scores = pd.read_csv(\"/opt/gpudata/rrg-data-2/inference-all/inf-results/cxr-mate/generations_findings_METRICS_2.csv\")\n",
    "cxrmate_text = pd.read_csv(\"/opt/gpudata/rrg-data-2/inference-all/inf-results/cxr-mate/generations_findings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexbert = f1chexbert.F1CheXbert(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexbert.get_label(\"triple-lumn catheter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexbert.get_label(\"PICC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexbert.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = scores.merge(cxrmate_scores, on=\"study_id\", suffixes=(\"_labrag\", \"_cxrmate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged[\"actual_chexbert_cxrmate\"] == merged[\"actual_chexbert_labrag\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\n",
    "    ((merged[\"f1chexbert_labrag\"] - merged[\"f1chexbert_cxrmate\"]).abs() <= 0.2)\n",
    "    & ((merged[\"f1radgraph_labrag\"] - merged[\"f1radgraph_cxrmate\"]).abs() > 0.2)\n",
    "    & (merged[\"generated_radgraph_labrag\"].str.len() < 4000)\n",
    "    & (merged[\"generated_radgraph_cxrmate\"].str.len() < 4000)\n",
    "].sort_values(\"f1radgraph_labrag\", ascending=True).sort_values(\"f1chexbert_labrag\", ascending=False, kind=\"stable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1346\n",
    "merged.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_radgraph = eval(merged.loc[idx, \"actual_radgraph_labrag\"])\n",
    "entities = []\n",
    "for _, entity in actual_radgraph[\"entities\"].items():\n",
    "    # print(entity[\"tokens\"])\n",
    "    entities.append(entity[\"tokens\"])\n",
    "print(\", \".join(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_radgraph = eval(merged.loc[idx, \"generated_radgraph_labrag\"])\n",
    "entities = []\n",
    "for _, entity in generated_radgraph[\"entities\"].items():\n",
    "    # print(entity[\"tokens\"])\n",
    "    entities.append(entity[\"tokens\"])\n",
    "print(\", \".join(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_radgraph = eval(merged.loc[idx, \"generated_radgraph_cxrmate\"])\n",
    "entities = []\n",
    "for _, entity in generated_radgraph[\"entities\"].items():\n",
    "    # print(entity[\"tokens\"])\n",
    "    entities.append(entity[\"tokens\"])\n",
    "print(\", \".join(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generations.loc[generations[\"study_id\"] == merged.loc[idx, \"study_id\"], \"actual_text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generations.loc[generations[\"study_id\"] == merged.loc[idx, \"study_id\"], \"generated_text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cxrmate_text.loc[cxrmate_text[\"study_id\"] == merged.loc[idx, \"study_id\"], \"generated_text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations.loc[generations[\"study_id\"] == merged.loc[idx, \"study_id\"]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids = [58732756, 57403810, 56254164, 50296928, 56714170, 51354687]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in metadata[metadata[\"study_id\"].isin(sids)].iterrows():\n",
    "    mrn = row[\"subject_id\"]\n",
    "    sid = row[\"study_id\"]\n",
    "    print(f\"/opt/gpudata/mimic-cxr/files/p{int(mrn/1000000)}/p{mrn}/s{sid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata[\"study_id\"].isin(sids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic_cxr_sectioned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sections.loc[sections[\"study_id\"] == 56254164, \"findings\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-chexpert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert.loc[chexpert[\"study_id\"] == 56714170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"study_id\"] == 58732756]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
