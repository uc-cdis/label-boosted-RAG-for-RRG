{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from _data import (\n",
    "    get_per_study_data,\n",
    "    get_split_features,\n",
    "    get_split_samples,\n",
    "    DEFAULT_PATIENT_ID_COL,\n",
    "    DEFAULT_STUDY_ID_COL,\n",
    "    DEFAULT_DICOM_ID_COL,\n",
    "    DEFAULT_SPLIT_COL,\n",
    "    DEFAULT_VIEW_COL,\n",
    "    DEFAULT_LABELS,\n",
    "    DEFAULT_VIEW_ORDER,\n",
    "    DEFAULT_FINDINGS_COL,\n",
    "    DEFAULT_IMPRESSION_COL,\n",
    "    DEFAULT_IMG_PROJ_KEY,\n",
    ")\n",
    "from _prompt import prepare_prompt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import trange\n",
    "import _prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieved_idxs(section_type):\n",
    "    _prompt.cached = None\n",
    "    split_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\"\n",
    "    metadata_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-metadata.csv\"\n",
    "    true_label_csv = \"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-chexpert.csv\"\n",
    "    predicted_label_csv = \"/opt/gpudata/rrg-data-2/image-labels/pred_pr.csv\"\n",
    "    label_type = \"pred\"\n",
    "    report_csv = \"/opt/gpudata/mimic-cxr/mimic_cxr_sectioned.csv\"\n",
    "    add_other_label = True\n",
    "    feature_h5 = \"/opt/gpudata/rrg-data-2/biovilt-features.h5\"\n",
    "    prompt_yaml = \"prompts.yaml\"\n",
    "    batch_size = 32\n",
    "    labels = DEFAULT_LABELS.copy()\n",
    "    prompt_type = \"simple\"\n",
    "\n",
    "    # TODO parameterize hardcoded split remapping\n",
    "    split_remap = {\n",
    "        \"train\": \"retrieval\",\n",
    "        \"validate\": \"retrieval\",\n",
    "        \"test\": \"inference\",\n",
    "    }\n",
    "\n",
    "    # Load and merge data relative to true labels\n",
    "    retrieval_df = get_per_study_data(\n",
    "        split_csv=split_csv,\n",
    "        metadata_csv=metadata_csv,\n",
    "        label_csv=true_label_csv,\n",
    "        report_csv=report_csv,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "        view_col=DEFAULT_VIEW_COL,\n",
    "        labels=labels,\n",
    "        view_order=DEFAULT_VIEW_ORDER,\n",
    "        report_cols=[DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL],\n",
    "        split_remap=split_remap,\n",
    "    )\n",
    "\n",
    "    # Load and merge data relative to predicted labels if provided\n",
    "    inference_df = get_per_study_data(\n",
    "        split_csv=split_csv,\n",
    "        metadata_csv=metadata_csv,\n",
    "        label_csv=predicted_label_csv or true_label_csv,\n",
    "        report_csv=report_csv,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "        view_col=DEFAULT_VIEW_COL,\n",
    "        labels=labels,\n",
    "        view_order=DEFAULT_VIEW_ORDER,\n",
    "        report_cols=[DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL],\n",
    "        split_remap=split_remap,\n",
    "    )\n",
    "\n",
    "    # Check that true and predicted labels result in same merged dataframes\n",
    "    cols = [DEFAULT_PATIENT_ID_COL, DEFAULT_STUDY_ID_COL, DEFAULT_DICOM_ID_COL, DEFAULT_SPLIT_COL, DEFAULT_VIEW_COL]\n",
    "    assert retrieval_df[cols].equals(inference_df[cols])\n",
    "\n",
    "    # Filter dataset to only those with given section type\n",
    "    if section_type == \"findings\":\n",
    "        report_cols = [DEFAULT_FINDINGS_COL]\n",
    "    elif section_type == \"impression\":\n",
    "        report_cols = [DEFAULT_IMPRESSION_COL]\n",
    "    elif section_type in [\"both\", \"findings-intersect\", \"impression-intersect\"]:\n",
    "        report_cols = [DEFAULT_FINDINGS_COL, DEFAULT_IMPRESSION_COL]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown section type: {section_type}\")\n",
    "\n",
    "    mask = retrieval_df[report_cols].notna().all(axis=1)\n",
    "    retrieval_df = retrieval_df[mask].reset_index(drop=True).copy()\n",
    "    inference_df = inference_df[mask].reset_index(drop=True).copy()\n",
    "\n",
    "    # Add implicit \"other\" label\n",
    "    if add_other_label:\n",
    "        # TODO does \"other\" definition depend on prompt type?\n",
    "        retrieval_df[\"Other\"] = (retrieval_df[labels] != 1).all(axis=1).astype(int)\n",
    "        inference_df[\"Other\"] = (inference_df[labels] != 1).all(axis=1).astype(int)\n",
    "        labels += [\"Other\"]\n",
    "\n",
    "    # Prepare per-split projected embeddings\n",
    "    features = get_split_features(\n",
    "        feature_h5=feature_h5,\n",
    "        feature_key=DEFAULT_IMG_PROJ_KEY,\n",
    "        sample_df=retrieval_df,\n",
    "        patient_id_col=DEFAULT_PATIENT_ID_COL,\n",
    "        study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "        dicom_id_col=DEFAULT_DICOM_ID_COL,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )\n",
    "    retrieval_features = features[\"retrieval\"]\n",
    "    inference_features = features[\"inference\"]\n",
    "\n",
    "    # Prepare per-split metadata, labels, and reports\n",
    "    retrieval_samples = get_split_samples(\n",
    "        sample_df=retrieval_df,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )[\"retrieval\"]\n",
    "    inference_samples = get_split_samples(\n",
    "        sample_df=inference_df,\n",
    "        split_col=DEFAULT_SPLIT_COL,\n",
    "    )[\"inference\"]\n",
    "\n",
    "    # Prepare prompt templates\n",
    "    with open(prompt_yaml) as f:\n",
    "        prompt_templates = yaml.safe_load(f)\n",
    "\n",
    "    # Compute similarity between inference and retrieval samples\n",
    "    similarity = cosine_similarity(inference_features, retrieval_features)\n",
    "\n",
    "    # Generate reports\n",
    "    N = len(inference_samples)\n",
    "\n",
    "    exact_filter_retrieved_idxs = []\n",
    "    for i in trange(N):\n",
    "        prompt, target_report, retrieved_studies, idxs = prepare_prompt(\n",
    "            retrieval_samples=retrieval_samples,\n",
    "            target_sample=inference_samples.iloc[i],\n",
    "            target_similarity=similarity[i],\n",
    "            k=5,\n",
    "            prompt_templates=prompt_templates,\n",
    "            filter_type=\"exact\",\n",
    "            prompt_type=prompt_type,\n",
    "            section_type=section_type,\n",
    "            labels=labels,\n",
    "            findings_col=DEFAULT_FINDINGS_COL,\n",
    "            impression_col=DEFAULT_IMPRESSION_COL,\n",
    "            study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "            return_relative_idxs=True,\n",
    "        )\n",
    "        exact_filter_retrieved_idxs.append(idxs)\n",
    "    \n",
    "    partial_filter_retrieved_idxs = []\n",
    "    for i in trange(N):\n",
    "        prompt, target_report, retrieved_studies, idxs = prepare_prompt(\n",
    "            retrieval_samples=retrieval_samples,\n",
    "            target_sample=inference_samples.iloc[i],\n",
    "            target_similarity=similarity[i],\n",
    "            k=5,\n",
    "            prompt_templates=prompt_templates,\n",
    "            filter_type=\"partial\",\n",
    "            prompt_type=prompt_type,\n",
    "            section_type=section_type,\n",
    "            labels=labels,\n",
    "            findings_col=DEFAULT_FINDINGS_COL,\n",
    "            impression_col=DEFAULT_IMPRESSION_COL,\n",
    "            study_id_col=DEFAULT_STUDY_ID_COL,\n",
    "            return_relative_idxs=True,\n",
    "        )\n",
    "        partial_filter_retrieved_idxs.append(idxs)\n",
    "    \n",
    "    return exact_filter_retrieved_idxs, partial_filter_retrieved_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_exact, findings_partial = get_retrieved_idxs(\"findings\")\n",
    "impression_exact, impression_partial = get_retrieved_idxs(\"impression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "cmap = sns.color_palette(palette=\"Set3\")\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\", figsize=(11, 5))\n",
    "\n",
    "gs = GridSpec(2, 3, figure=fig, width_ratios=[5, 5, 1])\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax_legend = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "bins = list(range(27))\n",
    "bins[-1] = 1000000\n",
    "\n",
    "sns.histplot([x - 1 for xs in findings_exact for x in xs], bins=bins, ax=ax1, color=cmap[4], linewidth=1, zorder=10, alpha=1)\n",
    "sns.histplot([x - 1 for xs in impression_exact for x in xs], bins=bins, ax=ax2, color=cmap[4], linewidth=1, zorder=10, alpha=1)\n",
    "sns.histplot([x - 1 for xs in findings_partial for x in xs], bins=bins, ax=ax3, color=cmap[1], linewidth=1, zorder=10, alpha=1)\n",
    "sns.histplot([x - 1 for xs in impression_partial for x in xs], bins=bins, ax=ax4, color=cmap[1], linewidth=1, zorder=10, alpha=1)\n",
    "\n",
    "ax1.set_ylim([0, 550])\n",
    "ax2.set_ylim([0, 550])\n",
    "ax3.set_ylim([0, 550])\n",
    "ax4.set_ylim([0, 550])\n",
    "\n",
    "ax1.set_xlim([0, 26])\n",
    "ax2.set_xlim([0, 26])\n",
    "ax3.set_xlim([0, 26])\n",
    "ax4.set_xlim([0, 26])\n",
    "\n",
    "ax1.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax2.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax3.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax4.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "ax3.set_xticklabels([0, 5, 10, 15, 20, \"25+\"])\n",
    "ax4.set_xticklabels([0, 5, 10, 15, 20, \"25+\"])\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax3.set_xlabel(\"Image Similarity Rank\")\n",
    "ax4.set_xlabel(\"Image Similarity Rank\")\n",
    "\n",
    "ax2.set_ylabel(\"\")\n",
    "ax4.set_ylabel(\"\")\n",
    "\n",
    "ax1.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax2.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax3.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "ax4.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "\n",
    "ax1.set_yticklabels([0, 100, 200, 300, 400, 500])\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([0, 100, 200, 300, 400, 500])\n",
    "ax4.set_yticklabels([])\n",
    "\n",
    "ax1.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax2.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax3.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "ax4.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "\n",
    "ax1.set_title(f\"Findings, N={len(findings_exact)}\")\n",
    "ax2.set_title(f\"Impression, N={len(impression_exact)}\")\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=cmap[4], edgecolor=\"gray\", label=\"Exact\"),\n",
    "    Patch(facecolor=cmap[1], edgecolor=\"gray\", label=\"Partial\"),\n",
    "]\n",
    "\n",
    "ax1_25n = (pd.Series([x - 1 for xs in findings_exact for x in xs]) >= 25).sum()\n",
    "ax1.text(25.6, 275, f\"{ax1_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\")\n",
    "ax2_25n = (pd.Series([x - 1 for xs in findings_partial for x in xs]) >= 25).sum()\n",
    "ax2.text(25.6, 275, f\"{ax2_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\")\n",
    "ax3_25n = (pd.Series([x - 1 for xs in impression_exact for x in xs]) >= 25).sum()\n",
    "ax3.text(25.6, 275, f\"{ax3_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\")\n",
    "ax4_25n = (pd.Series([x - 1 for xs in impression_partial for x in xs]) >= 25).sum()\n",
    "ax4.text(25.6, 275, f\"{ax4_25n}\", zorder=15, rotation=90, ha=\"center\", va=\"center\")\n",
    "\n",
    "ax_legend.legend(handles=legend_elements, loc=\"center left\", title=\"Filter\", title_fontproperties={\"weight\": \"semibold\"})\n",
    "ax_legend.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Top 5 Filtered Image Similarity\", x=0.47)\n",
    "\n",
    "fig.savefig(f\"../figs/pngs/filter-rank-hist.png\", dpi=300)\n",
    "fig.savefig(f\"../figs/pdfs/filter-rank-hist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
