{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rrg/prompts.yaml\") as f:\n",
    "    prompts = yaml.safe_load(f)\n",
    "\n",
    "def diff(a: str, b: str):\n",
    "    a = a.splitlines(keepends=True)\n",
    "    b = b.splitlines(keepends=True)\n",
    "    diff = difflib.unified_diff(a, b)\n",
    "    print(\"\".join(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"naive\"], prompts[\"simple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"simple\"], prompts[\"verbose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"verbose\"], prompts[\"instruct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install from source while waiting for merge of https://github.com/trevismd/statannotations/pull/155\n",
    "# !pip install https://github.com/getzze/statannotations/archive/compat-seaborn-13.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"Findings - Model\": [\n",
    "        (\"LaB-RAG\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"RGRG\", \"/opt/gpudata/rrg-data-2/exp-baseline/rgrg_findings_METRICS.csv\"),\n",
    "        (\"CheXagent\", \"/opt/gpudata/rrg-data-2/exp-baseline/chexagent_findings_METRICS.csv\"),\n",
    "        (\"CXRMate\", \"/opt/gpudata/rrg-data-2/exp-baseline/cxr-mate_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Model\": [\n",
    "        (\"LaB-RAG\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"CXR-RePaiR\", \"/opt/gpudata/rrg-data-2/exp-baseline/cxr-repair_impression_METRICS.csv\"),\n",
    "        (\"CXR-ReDonE\", \"/opt/gpudata/rrg-data-2/exp-baseline/cxr-redone_impression_METRICS.csv\"),\n",
    "        (\"X-REM\", \"/opt/gpudata/rrg-data-2/exp-baseline/x-rem_impression_METRICS.csv\"),\n",
    "        (\"CheXagent\", \"/opt/gpudata/rrg-data-2/exp-baseline/chexagent_impression_METRICS.csv\"),\n",
    "        (\"CXRMate\", \"/opt/gpudata/rrg-data-2/exp-baseline/cxr-mate_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Both - Model\": [\n",
    "        (\"LaB-RAG\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"CheXagent\", \"/opt/gpudata/rrg-data-2/exp-baseline/chexagent_both_METRICS.csv\"),\n",
    "        (\"CXRMate\", \"/opt/gpudata/rrg-data-2/exp-baseline/cxr-mate_both_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Filter\": [\n",
    "        (\"No-filter\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Exact\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Partial\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Prompt\": [\n",
    "        (\"Naive\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"Simple\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Verbose\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_findings_METRICS.csv\"),\n",
    "        (\"Instruct\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Language Model\": [\n",
    "        (\"Mistral-v1\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"BioMistral\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/BioMistral-7B_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Mistral-v3\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Label\": [\n",
    "        (\"True\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-label/Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Predicted\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-label/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Filter & Prompt\": [\n",
    "        (\"Standard RAG\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"Label Filter only\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"Label Format only\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"LaB-RAG\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Filter\": [\n",
    "        (\"No-filter\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Exact\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Partial\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Prompt\": [\n",
    "        (\"Naive\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"Simple\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Verbose\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_impression_METRICS.csv\"),\n",
    "        (\"Instruct\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Language Model\": [\n",
    "        (\"Mistral-v1\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"BioMistral\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/BioMistral-7B_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Mistral-v3\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Label\": [\n",
    "        (\"True\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-label/Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Predicted\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-label/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Filter & Prompt\": [\n",
    "        (\"Standard RAG\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"Label Filter only\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"Label Format only\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"LaB-RAG\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Section\": [\n",
    "        (\"Findings-Intersect\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings-intersect_METRICS.csv\"),\n",
    "        (\"Impression-Intersect\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression-intersect_METRICS.csv\"),\n",
    "        (\"Both\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_both_METRICS.csv\"),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check duplicate runs are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(list)\n",
    "for g, ts in experiments.items():\n",
    "    for _, t in ts:\n",
    "        base = os.path.basename(t)\n",
    "        count[base].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(l) for l in count.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = {k: v for k, v in count.items() if len(v) > 1}\n",
    "print(len(dupes))\n",
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric annotation cols (for radgraph and chexbert) are hard to compare\n",
    "# with np.isclose but should be same if derived metrics are the same\n",
    "cols = [\"study_id\", \"bleu4\", \"rougeL\", \"bertscore\", \"f1radgraph\", \"f1chexbert\"]\n",
    "for group, runs in dupes.items():\n",
    "    group_dfs = []\n",
    "    for run in runs:\n",
    "        df = pd.read_csv(run)\n",
    "        group_dfs.append(df)\n",
    "    ref = group_dfs[0]\n",
    "    for df, run in zip(group_dfs[1:], runs):\n",
    "        print(run)\n",
    "        assert np.isclose(ref[cols], df[cols]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map colors to experiments\n",
    "sorted(list(count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def lighten_color(color, amount=0.5):\n",
    "    \"\"\"\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette(palette='Set3')\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_cmap = sns.color_palette(palette='CMRmap')\n",
    "baseline_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\n",
    "    lighten_color(baseline_cmap[0], 0.6): [\n",
    "        \"chexagent_both_METRICS.csv\",\n",
    "        \"chexagent_findings_METRICS.csv\",\n",
    "        \"chexagent_impression_METRICS.csv\",\n",
    "    ],\n",
    "    baseline_cmap[2]: [\n",
    "        \"cxr-mate_both_METRICS.csv\",\n",
    "        \"cxr-mate_findings_METRICS.csv\",\n",
    "        \"cxr-mate_impression_METRICS.csv\",\n",
    "    ],\n",
    "    lighten_color(baseline_cmap[1], 0.7): [\n",
    "        \"cxr-redone_impression_METRICS.csv\",\n",
    "    ],\n",
    "    baseline_cmap[3]: [\n",
    "        \"cxr-repair_impression_METRICS.csv\",\n",
    "    ],\n",
    "    baseline_cmap[4]: [\n",
    "        \"rgrg_findings_METRICS.csv\",\n",
    "    ],\n",
    "    baseline_cmap[5]: [\n",
    "        \"x-rem_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[0]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[1]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[4]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_both_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[2]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[3]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[5]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[6]: [\n",
    "        \"Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[7]: [\n",
    "        \"BioMistral-7B_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"BioMistral-7B_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[8]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[9]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[10]: [\"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings-intersect_METRICS.csv\"],\n",
    "    cmap[11]: [\"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression-intersect_METRICS.csv\"],\n",
    "}\n",
    "colors = {v: k for k, vs in temp.items() for v in vs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"bleu4\",\n",
    "    \"rougeL\",\n",
    "    \"bertscore\",\n",
    "    \"f1radgraph\",\n",
    "    \"f1chexbert\",\n",
    "]\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "os.makedirs(\"figs-full\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, folder, extra_room=False):\n",
    "    for i, (group, runs) in enumerate(experiments.items()):\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        print(group)\n",
    "        group_results = []\n",
    "        for name, run in experiments[group]:\n",
    "            results = pd.read_csv(run)\n",
    "            group_results.append(results)\n",
    "\n",
    "        # intersection of study ids\n",
    "        study_ids = set(group_results[0][\"study_id\"])\n",
    "        for results in group_results[1:]:\n",
    "            study_ids &= set(results[\"study_id\"])\n",
    "        study_ids = sorted(list(study_ids))\n",
    "        group_results = [results.set_index(\"study_id\").loc[study_ids].reset_index() for results in group_results]\n",
    "\n",
    "        melted_results = []\n",
    "        for results, (name, _) in zip(group_results, experiments[group]):\n",
    "            results = results.melt(id_vars=\"study_id\", var_name=\"metric\")\n",
    "            results[group] = name\n",
    "            melted_results.append(results)\n",
    "\n",
    "        df = pd.concat(melted_results, ignore_index=True)\n",
    "        df = df[df[\"metric\"].isin(metrics)]\n",
    "        x = \"metric\"\n",
    "        y = \"value\"\n",
    "        hue = group\n",
    "        hue_order = [n for n, _ in experiments[group]]\n",
    "        palette = [colors[os.path.basename(fp)] for _, fp in experiments[group]]\n",
    "        order = metrics\n",
    "        if group in {\n",
    "            \"Findings - Model\",\n",
    "            \"Impression - Model\",\n",
    "            \"Both - Model\",\n",
    "        }:\n",
    "            # only compare to ours if evaluating literature models\n",
    "            pairs = [\n",
    "                ((metric, \"LaB-RAG\"), (metric, n2))\n",
    "                for metric in metrics\n",
    "                for n2 in hue_order[1:]\n",
    "            ]\n",
    "        else:\n",
    "            pairs = [\n",
    "                ((metric, n1), (metric, n2))\n",
    "                for metric in metrics\n",
    "                for i, n1 in enumerate(hue_order)\n",
    "                for n2 in hue_order[i+1:]\n",
    "            ]\n",
    "        if extra_room:\n",
    "            fig, ax = plt.subplots(figsize=(6, 3))\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(3, 3))\n",
    "        barplot = sns.barplot(\n",
    "            df,\n",
    "            x=x,\n",
    "            y=y,\n",
    "            order=order,\n",
    "            hue=hue,\n",
    "            hue_order=hue_order,\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            saturation=1,\n",
    "            zorder=15,\n",
    "            errorbar=\"se\",\n",
    "            # capsize=0.2,\n",
    "            err_kws={\n",
    "                \"zorder\": 25,\n",
    "                \"linewidth\": 1,\n",
    "                \"alpha\": 1,\n",
    "            },\n",
    "            width=0.15*len(hue_order),\n",
    "        )\n",
    "        # Box plot\n",
    "        # for bar in barplot.patches:\n",
    "        #     bar.set_width(0.5)\n",
    "        # sns.boxplot(\n",
    "        #     df,\n",
    "        #     x=x,\n",
    "        #     y=y,\n",
    "        #     order=order,\n",
    "        #     hue=hue,\n",
    "        #     hue_order=hue_order,\n",
    "        #     palette=palette,\n",
    "        #     ax=ax,\n",
    "        #     fliersize=0.1,\n",
    "        #     showmeans=True,\n",
    "        #     meanprops={\n",
    "        #         \"markersize\": 5,\n",
    "        #         \"markeredgecolor\": \"black\",\n",
    "        #         \"marker\": \"+\",\n",
    "        #         # \"marker\": \"P\",\n",
    "        #         # \"markerfacecolor\": \"black\",\n",
    "        #         # \"markeredgecolor\": \"darkgray\",\n",
    "        #         # \"markeredgewidth\": 1,\n",
    "        #     },\n",
    "        #     saturation=1,\n",
    "        # )\n",
    "        annot = Annotator(\n",
    "            ax,\n",
    "            pairs,\n",
    "            data=df,\n",
    "            x=x,\n",
    "            y=y,\n",
    "            order=order,\n",
    "            hue=hue,\n",
    "            hue_order=hue_order,\n",
    "            palette=palette,\n",
    "            width=0.15*len(hue_order),\n",
    "        )\n",
    "        # test = \"t-test_paired\" if group not in [\"Section\", \"Section-true\"] else \"t-test_ind\"\n",
    "        test = \"t-test_paired\"\n",
    "        annot._pvalue_format.fontsize = 9\n",
    "        annot.configure(\n",
    "            test=test,\n",
    "            comparisons_correction=\"Bonferroni\",\n",
    "            hide_non_significant=True,\n",
    "            # loc=\"outside\",\n",
    "            line_height=0.04,\n",
    "            text_offset=-3,\n",
    "            line_offset=10000,\n",
    "            line_offset_to_group=0.1,\n",
    "            line_width=0.75,\n",
    "            pvalue_thresholds=[[0.05, \"*\"], [1, \"ns\"]],\n",
    "        )\n",
    "        _, annotations = annot.apply_test().annotate(line_offset=10000)\n",
    "        # print(annotations[0].structs)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        if extra_room:\n",
    "            ax.set_ylim([-0.05, 1.55])\n",
    "        else:\n",
    "            ax.set_ylim([-0.05, 1.05])\n",
    "        ax.set_xlim([-0.5, len(metrics) - 0.5])\n",
    "        ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        ax.grid(which=\"major\", axis=\"y\", zorder=0)\n",
    "        ax.set_title(f\"{group.split(' - ')[0]}, N={len(study_ids)}\", fontsize=10)\n",
    "        legend = ax.legend(title=None, loc=\"upper left\")\n",
    "        legend.set_zorder(10)\n",
    "        # legend.remove()\n",
    "        fig.show()\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"{folder}/{group}.pdf\")\n",
    "\n",
    "        # fig2, ax2 = plt.subplots(figsize=(3, 2))\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # ax2.legend(handles, labels, loc=\"center\")\n",
    "        # ax2.axis(\"off\")\n",
    "        # fig2.savefig(f\"{folder}/legends/{group}-legend.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics=[\"f1radgraph\", \"f1chexbert\"], folder=\"figs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics=[\"bleu4\", \"rougeL\", \"bertscore\", \"f1radgraph\", \"f1chexbert\"], folder=\"figs-full\", extra_room=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC/PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from classify import plot_pr_curve, plot_roc_curve\n",
    "from _data import DEFAULT_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"/opt/gpudata/rrg-data-2/image-labels/test_true.csv\")\n",
    "y_prob_test = pd.read_csv(\"/opt/gpudata/rrg-data-2/image-labels/test_prob.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(\n",
    "    df_trues=y_test,\n",
    "    df_probs=y_prob_test,\n",
    "    labels=DEFAULT_LABELS,\n",
    "    title=f\"Test ROC Curve\",\n",
    "    output_path=\"figs/Classifier ROC Curve.pdf\",\n",
    ")\n",
    "\n",
    "plot_pr_curve(\n",
    "    df_trues=y_test,\n",
    "    df_probs=y_prob_test,\n",
    "    labels=DEFAULT_LABELS,\n",
    "    title=f\"Test PR Curve\",\n",
    "    output_path=\"figs/Classifier PR Curve.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"bleu4\", \"rougeL\", \"bertscore\", \"f1radgraph\", \"f1chexbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for group, runs in experiments.items():\n",
    "    parts = group.split(\" - \")\n",
    "    if len(parts) > 1:\n",
    "        section = parts[0]\n",
    "        experiment = parts[1]\n",
    "    else:\n",
    "        experiment = group\n",
    "        section = \"Intersection\"\n",
    "    for run_name, run_path in runs:\n",
    "        temp = pd.read_csv(run_path)[metrics].mean()\n",
    "        temp.name = (experiment, section, run_name)\n",
    "        results.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(e.split(\" - \")[1], e.split(\" - \")[0], n) for e, nps in experiments.items() for n, p in nps if e != \"Section\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    (\"Model\", \"Findings\", \"LaB-RAG\"),\n",
    "    (\"Model\", \"Findings\", \"RGRG\"),\n",
    "    (\"Model\", \"Findings\", \"CheXagent\"),\n",
    "    (\"Model\", \"Findings\", \"CXRMate\"),\n",
    "    (\"Model\", \"Impression\", \"LaB-RAG\"),\n",
    "    (\"Model\", \"Impression\", \"CXR-RePaiR\"),\n",
    "    (\"Model\", \"Impression\", \"CXR-ReDonE\"),\n",
    "    (\"Model\", \"Impression\", \"X-REM\"),\n",
    "    (\"Model\", \"Impression\", \"CheXagent\"),\n",
    "    (\"Model\", \"Impression\", \"CXRMate\"),\n",
    "    (\"Model\", \"Both\", \"LaB-RAG\"),\n",
    "    (\"Model\", \"Both\", \"CheXagent\"),\n",
    "    (\"Model\", \"Both\", \"CXRMate\"),\n",
    "    # ==================================================================\n",
    "    (\"Filter & Prompt\", \"Findings\", \"Standard RAG\"),\n",
    "    (\"Filter & Prompt\", \"Findings\", \"Label Filter only\"),\n",
    "    (\"Filter & Prompt\", \"Findings\", \"Label Format only\"),\n",
    "    (\"Filter & Prompt\", \"Findings\", \"LaB-RAG\"),\n",
    "    (\"Filter & Prompt\", \"Impression\", \"Standard RAG\"),\n",
    "    (\"Filter & Prompt\", \"Impression\", \"Label Filter only\"),\n",
    "    (\"Filter & Prompt\", \"Impression\", \"Label Format only\"),\n",
    "    (\"Filter & Prompt\", \"Impression\", \"LaB-RAG\"),\n",
    "    # ==================================================================\n",
    "    (\"Filter\", \"Findings\", \"No-filter\"),\n",
    "    (\"Filter\", \"Findings\", \"Exact\"),\n",
    "    (\"Filter\", \"Findings\", \"Partial\"),\n",
    "    (\"Filter\", \"Impression\", \"No-filter\"),\n",
    "    (\"Filter\", \"Impression\", \"Exact\"),\n",
    "    (\"Filter\", \"Impression\", \"Partial\"),\n",
    "    # ==================================================================\n",
    "    (\"Prompt\", \"Findings\", \"Naive\"),\n",
    "    (\"Prompt\", \"Findings\", \"Simple\"),\n",
    "    (\"Prompt\", \"Findings\", \"Verbose\"),\n",
    "    (\"Prompt\", \"Findings\", \"Instruct\"),\n",
    "    (\"Prompt\", \"Impression\", \"Naive\"),\n",
    "    (\"Prompt\", \"Impression\", \"Simple\"),\n",
    "    (\"Prompt\", \"Impression\", \"Verbose\"),\n",
    "    (\"Prompt\", \"Impression\", \"Instruct\"),\n",
    "    # ==================================================================\n",
    "    (\"Language Model\", \"Findings\", \"Mistral-v1\"),\n",
    "    (\"Language Model\", \"Findings\", \"BioMistral\"),\n",
    "    (\"Language Model\", \"Findings\", \"Mistral-v3\"),\n",
    "    (\"Language Model\", \"Impression\", \"Mistral-v1\"),\n",
    "    (\"Language Model\", \"Impression\", \"BioMistral\"),\n",
    "    (\"Language Model\", \"Impression\", \"Mistral-v3\"),\n",
    "    # ==================================================================\n",
    "    (\"Label\", \"Findings\", \"True\"),\n",
    "    (\"Label\", \"Findings\", \"Predicted\"),\n",
    "    (\"Label\", \"Impression\", \"True\"),\n",
    "    (\"Label\", \"Impression\", \"Predicted\"),\n",
    "    # ==================================================================\n",
    "    (\"Section\", \"Intersection\", \"Findings-Intersect\"),\n",
    "    (\"Section\", \"Intersection\", \"Impression-Intersect\"),\n",
    "    (\"Section\", \"Intersection\", \"Both\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_index(level=0, inplace=True)\n",
    "results.index.set_names([\"experiment\", \"section\", \"variable\"], inplace=True)\n",
    "results = results.loc[rows].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = results.style.format(precision=3).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\\\cline{2-8}\\n & \\\\multirow\".join(\"\\n\\\\cline{1-8}\\n\\\\multirow\".join(latex.split(\"\\n\\\\multirow\")).split(\"\\n & \\\\multirow\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from _data import DEFAULT_VIEW_ORDER\n",
    "\n",
    "view_idx = {k: i for i, k in enumerate(DEFAULT_VIEW_ORDER)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {split: pd.read_csv(f\"/opt/gpudata/rrg-data-2/image-labels/{split}_true.csv\") for split in [\"train\", \"val\", \"test\"]}\n",
    "view_counts = pd.DataFrame({split: df[\"ViewPosition\"].value_counts() for split, df in splits.items()}).fillna(0).astype(int).sort_index(key=lambda xs: [view_idx[x] for x in xs])\n",
    "view_counts[\"overall\"] = view_counts.sum(axis=1)\n",
    "view_counts = view_counts[[\"overall\", \"train\", \"val\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = pd.Series({split: len(df.drop_duplicates(\"study_id\")) for split, df in splits.items()})\n",
    "lens.loc[\"overall\"] = lens.sum()\n",
    "lens = lens[[\"overall\", \"train\", \"val\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_counts = view_counts.astype(str) + \" (\" + (view_counts / lens * 100).map(lambda x: f\"{x:.1f}\") + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(view_counts.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectioned = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic_cxr_sectioned.csv\")\n",
    "splits = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splits[[\"study_id\", \"subject_id\", \"split\"]].drop_duplicates()\n",
    "merged = sectioned.merge(splits, on=\"study_id\")\n",
    "merged[\"impression\"] = merged[\"impression\"].notna()\n",
    "merged[\"findings\"] = merged[\"findings\"].notna()\n",
    "merged[\"both\"] = merged[\"impression\"] & merged[\"findings\"]\n",
    "merged.loc[merged[\"split\"] == \"validate\", \"split\"] = \"val\"\n",
    "temp = pd.DataFrame({\n",
    "    \"impression\": merged.groupby(\"split\")[\"impression\"].value_counts(),\n",
    "    \"findings\": merged.groupby(\"split\")[\"findings\"].value_counts(),\n",
    "    \"both\": merged.groupby(\"split\")[\"both\"].value_counts(),\n",
    "}).iloc[[1,3,5]].reset_index(level=1, drop=True).T\n",
    "temp.index.name = \"section\"\n",
    "temp = temp[[\"train\", \"val\", \"test\"]]\n",
    "temp[\"overall\"] = temp.sum(axis=1)\n",
    "temp = temp[[\"overall\", \"train\", \"val\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = splits.drop_duplicates(\"study_id\").groupby(\"split\").size().rename({\"validate\": \"val\"})\n",
    "lens.loc[\"overall\"] = lens.sum()\n",
    "lens = lens[[\"overall\", \"train\", \"val\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.astype(str) + \" (\" + (temp / lens * 100).map(lambda x: f\"{x:.1f}\") +  \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tableone import TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edstays = pd.read_csv(\"/opt/gpudata/mimic/iv/ed/edstays.csv.gz\")\n",
    "patients = pd.read_csv(\"/opt/gpudata/mimic/iv/hosp/patients.csv.gz\")\n",
    "metadata = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-metadata.csv\")\n",
    "splits = pd.read_csv(\"/opt/gpudata/mimic-cxr/mimic-cxr-2.0.0-split.csv\")\n",
    "splits = splits[[\"study_id\", \"subject_id\", \"split\"]].drop_duplicates()\n",
    "splits[\"split\"] = splits[\"split\"].replace({\"validate\": \"val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"WHITE\": \"White\",\n",
    "    \"BLACK/AFRICAN AMERICAN\": \"Black\",\n",
    "    \"OTHER\": \"Other\",\n",
    "    \"UNKNOWN\": \"Unknown\",\n",
    "    \"ASIAN\": \"Asian\",\n",
    "    \"HISPANIC/LATINO - PUERTO RICAN\": \"Hispanic or Latino\",\n",
    "    \"WHITE - OTHER EUROPEAN\": \"White\",\n",
    "    \"ASIAN - CHINESE\": \"Asian\",\n",
    "    \"HISPANIC/LATINO - DOMINICAN\": \"Hispanic or Latino\",\n",
    "    \"BLACK/CAPE VERDEAN\": \"Black\",\n",
    "    \"BLACK/AFRICAN\": \"Black\",\n",
    "    \"WHITE - RUSSIAN\": \"White\",\n",
    "    \"HISPANIC OR LATINO\": \"Hispanic or Latino\",\n",
    "    \"BLACK/CARIBBEAN ISLAND\": \"Black\",\n",
    "    \"HISPANIC/LATINO - GUATEMALAN\": \"Hispanic or Latino\",\n",
    "    \"ASIAN - ASIAN INDIAN\": \"Asian\",\n",
    "    \"ASIAN - SOUTH EAST ASIAN\": \"Asian\",\n",
    "    \"WHITE - BRAZILIAN\": \"White\",\n",
    "    \"HISPANIC/LATINO - MEXICAN\": \"Hispanic or Latino\",\n",
    "    \"HISPANIC/LATINO - SALVADORAN\": \"Hispanic or Latino\",\n",
    "    \"WHITE - EASTERN EUROPEAN\": \"White\",\n",
    "    \"HISPANIC/LATINO - COLUMBIAN\": \"Hispanic or Latino\",\n",
    "    \"PORTUGUESE\": \"Other\",\n",
    "    \"AMERICAN INDIAN/ALASKA NATIVE\": \"American Indian or Alaska Native\",\n",
    "    \"SOUTH AMERICAN\": \"Other\",\n",
    "    \"PATIENT DECLINED TO ANSWER\": \"Unknown\",\n",
    "    \"ASIAN - KOREAN\": \"Asian\",\n",
    "    \"HISPANIC/LATINO - HONDURAN\": \"Hispanic or Latino\",\n",
    "    \"HISPANIC/LATINO - CENTRAL AMERICAN\": \"Hispanic or Latino\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\": \"Native Hawaiian or Pacific Islander\",\n",
    "    \"HISPANIC/LATINO - CUBAN\": \"Hispanic or Latino\",\n",
    "    \"UNABLE TO OBTAIN\": \"Unknown\",\n",
    "    \"MULTIPLE RACE/ETHNICITY\": \"Other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stay_race = edstays.sort_values(by=[\"subject_id\", \"intime\"], ascending=True).drop_duplicates(subset=\"subject_id\", keep=\"last\")[[\"subject_id\", \"race\"]]\n",
    "last_stay_race[\"race\"] = last_stay_race[\"race\"].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"study_year\"] = metadata[\"StudyDate\"].astype(str).str[:4].astype(int)\n",
    "study_year = metadata[[\"subject_id\", \"study_id\", \"study_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not last_stay_race[[\"subject_id\", \"race\"]].drop_duplicates()[\"subject_id\"].duplicated(keep=False).any()\n",
    "assert not patients[\"subject_id\"].duplicated().any()\n",
    "assert not last_stay_race[\"subject_id\"].duplicated().any()\n",
    "assert not study_year[[\"subject_id\", \"study_id\", \"study_year\"]].drop_duplicates()[[\"subject_id\", \"study_id\"]].duplicated(keep=False).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    splits.merge(patients, on=\"subject_id\", how=\"left\")\n",
    "    .merge(last_stay_race, on=\"subject_id\", how=\"left\")\n",
    "    .merge(study_year.drop_duplicates([\"subject_id\", \"study_id\"]), on=[\"subject_id\", \"study_id\"], how=\"left\")\n",
    ").rename(columns={\"gender\": \"sex\"})\n",
    "\n",
    "merged[\"year_diff\"] = merged[\"study_year\"] - merged[\"anchor_year\"]\n",
    "merged[\"age\"] = merged[\"anchor_age\"] + merged[\"year_diff\"]\n",
    "merged[\"sex\"] = merged[\"sex\"].replace({\"F\": \"Female\", \"M\": \"Male\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert splits[\"split\"].value_counts().equals(merged[\"split\"].value_counts())\n",
    "assert not merged[\"study_id\"].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = \"split\"\n",
    "columns = [\"age\", \"sex\", \"race\"]\n",
    "categorical = [\"sex\", \"race\"]\n",
    "continuous = [\"age\"]\n",
    "nonnormal=[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = TableOne(\n",
    "    data=merged,\n",
    "    columns=columns,\n",
    "    categorical=categorical,\n",
    "    continuous=continuous,\n",
    "    groupby=groupby,\n",
    "    nonnormal=nonnormal,\n",
    "    overall=True,\n",
    "    include_null=False\n",
    ")\n",
    "table = table.tableone.droplevel(level=0, axis=\"columns\")[[\"Overall\", \"train\", \"val\", \"test\"]].rename(columns={\"Overall\": \"overall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = merged[[\"split\", \"age\"]].copy()\n",
    "temp[\"age\"] = temp[\"age\"].isna()\n",
    "missing = temp.groupby(\"split\")[\"age\"].sum()\n",
    "missing.loc[\"overall\"] = temp[\"age\"].sum()\n",
    "sizes = temp.groupby(\"split\").size()\n",
    "sizes.loc[\"overall\"] = len(temp)\n",
    "table.loc[(\"age, median [Q1,Q3]\", \"Missing\"), :] = (missing.astype(str) + \" (\" + (missing / sizes).map(lambda x: f\"{x*100:.1f}\") + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = merged[[\"split\", \"sex\"]].copy()\n",
    "temp[\"sex\"] = temp[\"sex\"].isna()\n",
    "missing = temp.groupby(\"split\")[\"sex\"].sum()\n",
    "missing.loc[\"overall\"] = temp[\"sex\"].sum()\n",
    "sizes = temp.groupby(\"split\").size()\n",
    "sizes.loc[\"overall\"] = len(temp)\n",
    "table.loc[(\"sex, n (%)\", \"Missing\"), :] = (missing.astype(str) + \" (\" + (missing / sizes).map(lambda x: f\"{x*100:.1f}\") + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = merged[[\"split\", \"race\"]].copy()\n",
    "temp[\"race\"] = temp[\"race\"].isna()\n",
    "missing = temp.groupby(\"split\")[\"race\"].sum()\n",
    "missing.loc[\"overall\"] = temp[\"race\"].sum()\n",
    "sizes = temp.groupby(\"split\").size()\n",
    "sizes.loc[\"overall\"] = len(temp)\n",
    "table.loc[(\"race, n (%)\", \"Missing\"), :] = (missing.astype(str) + \" (\" + (missing / sizes).map(lambda x: f\"{x*100:.1f}\") + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = merged.drop_duplicates(\"subject_id\")[\"split\"].value_counts()\n",
    "temp.loc[\"overall\"] = temp.sum()\n",
    "table.loc[(\"n\", \"Patients\"), :] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1, k2 in {\n",
    "    (\"n\", \"\"): (\"n\", \"Studies\"),\n",
    "    (\"age, median [Q1,Q3]\", \"\"): (\"age\", \"Median [Q1,Q3]\"),\n",
    "    (\"age, median [Q1,Q3]\", \"Missing\"): (\"age\", \"Missing, n (%)\"),\n",
    "}.items():\n",
    "    table.loc[k2, :] = table.loc[k1].copy()\n",
    "    table.drop(index=k1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.sort_index().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
