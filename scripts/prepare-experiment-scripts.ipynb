{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_preamble():\n",
    "    # this gets flagged by detect secrets if done in multiline string, no way to flag false positive for specific lines in multiline\n",
    "    return \"REPO_ROOT=/opt/gpudata/steven/label-boosted-RAG-for-RRG\\nMIMIC_CXR_DIR=/opt/gpudata/mimic-cxr\\nCHEXPERTPLUS_DIR=/opt/gpudata/chexpertplus\\nLABEL_DIR=/opt/gpudata/cxr-derived\\nBASE_OUTPUT_DIR=/opt/gpudata/labrag\\n\\nset -e\\n\"\n",
    "\n",
    "def get_exp_str(**kwargs):\n",
    "    label_type = \"true\"\n",
    "    if kwargs[\"pred_label_csv\"] not in [\"None\", \"none\", \"''\", '\"\"']:\n",
    "        label_type = f\"{os.path.basename(kwargs['emb_h5'].replace('.h5', ''))}-pred\"\n",
    "    kwargs[\"label_type\"] = label_type\n",
    "\n",
    "    kwargs[\"model_name\"] = os.path.basename(kwargs[\"llm\"])\n",
    "\n",
    "    return \"\"\"\n",
    "python $REPO_ROOT/rrg/generate.py \\\\\n",
    "--model {llm} \\\\\n",
    "--filter_type {filter} \\\\\n",
    "--prompt_type {prompt} \\\\\n",
    "--section_type {section} \\\\\n",
    "--k {k} \\\\\n",
    "--batch_size 32 \\\\\n",
    "--prompt_yaml $REPO_ROOT/rrg/prompts.yaml \\\\\n",
    "--split_csv {split_csv} \\\\\n",
    "--metadata_csv {metadata_csv} \\\\\n",
    "--true_label_csv {true_label_csv} \\\\\n",
    "--predicted_label_csv {pred_label_csv} \\\\\n",
    "--report_csv {report_csv} \\\\\n",
    "--feature_h5 {emb_h5} \\\\\n",
    "--output_dir {output_dir}\n",
    "\n",
    "python $REPO_ROOT/rrg/eval.py \\\\\n",
    "--report_csv {output_dir}/{section}_top-{k}_{label_type}-label_{filter}_{prompt}_{model_name}.csv \\\\\n",
    "--output_csv {output_dir}/{section}_top-{k}_{label_type}-label_{filter}_{prompt}_{model_name}_METRICS.csv\n",
    "\"\"\".format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LLM = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "DEFAULT_FILTER = \"exact\"\n",
    "DEFAULT_PROMPT = \"simple\"\n",
    "DEFAULT_K = 5\n",
    "\n",
    "for dataset in [\"mimic\", \"chexpertplus\"]:\n",
    "    if dataset == \"mimic\":\n",
    "        split_csv = \"$MIMIC_CXR_DIR/mimic-cxr-2.0.0-split.csv\"\n",
    "        metadata_csv = \"$MIMIC_CXR_DIR/mimic-cxr-2.0.0-metadata.csv\"\n",
    "        report_csv = \"$MIMIC_CXR_DIR/mimic_cxr_sectioned.csv\"\n",
    "        emb_model = \"biovilt\"\n",
    "        emb_h5 = f\"$BASE_OUTPUT_DIR/mimic-cxr-{emb_model}.h5\"\n",
    "    elif dataset == \"chexpertplus\":\n",
    "        split_csv = \"$CHEXPERTPLUS_DIR/split.csv\"\n",
    "        metadata_csv = \"$CHEXPERTPLUS_DIR/metadata.csv\"\n",
    "        report_csv = \"$CHEXPERTPLUS_DIR/report.csv\"\n",
    "        emb_model = \"gloria\"\n",
    "        emb_h5 = f\"$BASE_OUTPUT_DIR/chexpertplus-{emb_model}.h5\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "\n",
    "    for section in [\"findings\", \"impression\"]:\n",
    "        script_file = f\"3-run-generate-eval-{dataset}-{section}.sh\"\n",
    "        true_label_csv = f\"$LABEL_DIR/{dataset}-{section}-labels.csv\"\n",
    "        pred_label_csv = f\"$BASE_OUTPUT_DIR/{dataset}-{section}-{emb_model}-classifiers/pred_pr.csv\"\n",
    "        output_dir = f\"$BASE_OUTPUT_DIR/exp-{dataset}/exp-{section}\"\n",
    "\n",
    "        base_kwargs = {\n",
    "            \"llm\": DEFAULT_LLM,\n",
    "            \"filter\": DEFAULT_FILTER,\n",
    "            \"prompt\": DEFAULT_PROMPT,\n",
    "            \"k\": DEFAULT_K,\n",
    "            \"section\": section,\n",
    "            \"split_csv\": split_csv,\n",
    "            \"metadata_csv\": metadata_csv,\n",
    "            \"report_csv\": report_csv,\n",
    "            \"true_label_csv\": true_label_csv,\n",
    "            \"pred_label_csv\": pred_label_csv,\n",
    "            \"emb_h5\": emb_h5,\n",
    "        }\n",
    "\n",
    "        cmds = []\n",
    "\n",
    "        cmds.append(\"# Core Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-core\"\n",
    "        for filter_type, prompt_type in [(\"no-filter\", \"naive\"), (\"exact\", \"naive\"), (\"no-filter\", \"simple\"), (\"exact\", \"simple\")]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"filter\"] = filter_type\n",
    "            kwargs[\"prompt\"] = prompt_type\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# Filter Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-filter\"\n",
    "        for filter_type in [\"no-filter\", \"exact\", \"partial\"]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"filter\"] = filter_type\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# Prompt Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-prompt\"\n",
    "        for prompt_type in [\"naive\", \"simple\", \"verbose\", \"instruct\"]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"prompt\"] = prompt_type\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# LLM Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-llm\"\n",
    "        for temp in [\"mistralai/Mistral-7B-Instruct-v0.3\", \"mistralai/Mistral-7B-Instruct-v0.1\", \"BioMistral/BioMistral-7B\"]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"llm\"] = temp\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# Embedding Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-embedding\"\n",
    "        for temp in [emb_model, \"resnet50\"]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"emb_h5\"] = f\"$BASE_OUTPUT_DIR/chexpertplus-{temp}.h5\"\n",
    "            kwargs[\"pred_label_csv\"] = f\"$BASE_OUTPUT_DIR/{dataset}-{section}-{temp}-classifiers/pred_pr.csv\"\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# True Label Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-true-label\"\n",
    "        for temp in [pred_label_csv, \"None\"]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"pred_label_csv\"] = temp\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        cmds.append(\"# Top K Experiments\")\n",
    "        base_kwargs[\"output_dir\"] = f\"{output_dir}/exp-top-k\"\n",
    "        for temp in [3, 5, 10]:\n",
    "            kwargs = base_kwargs.copy()\n",
    "            kwargs[\"k\"] = temp\n",
    "            cmds.append(get_exp_str(**kwargs))\n",
    "\n",
    "        with open(script_file, \"w\") as f:\n",
    "            f.write(get_preamble())\n",
    "            for cmd in cmds:\n",
    "                if cmd.startswith(\"#\"):\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(\"# =================================\\n\")\n",
    "                    f.write(cmd + \"\\n\")\n",
    "                    f.write(\"# =================================\\n\")\n",
    "                else:\n",
    "                    f.write(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
