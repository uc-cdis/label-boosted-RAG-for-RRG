{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rrg/prompts.yaml\") as f:\n",
    "    prompts = yaml.safe_load(f)\n",
    "\n",
    "def diff(a: str, b: str):\n",
    "    a = a.splitlines(keepends=True)\n",
    "    b = b.splitlines(keepends=True)\n",
    "    diff = difflib.unified_diff(a, b)\n",
    "    print(\"\".join(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"naive\"], prompts[\"simple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"simple\"], prompts[\"verbose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(prompts[\"verbose\"], prompts[\"instruct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install from source while waiting for merge of https://github.com/trevismd/statannotations/pull/155\n",
    "# !pip install https://github.com/getzze/statannotations/archive/compat-seaborn-13.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"Findings - Filter\": [\n",
    "        (\"No-filter\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Exact\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Partial\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-filter/Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Prompt\": [\n",
    "        (\"Naive\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"Simple\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Verbose\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_findings_METRICS.csv\"),\n",
    "        (\"Instruct\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Model\": [\n",
    "        (\"Mistral-v3\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Mistral-v1\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"BioMistral\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-model/BioMistral-7B_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Label\": [\n",
    "        (\"True\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-label/Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Predicted\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-label/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Findings - Redundancy\": [\n",
    "        (\"No-filter, Naive-prompt\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"No-filter, Simple-prompt\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "        (\"Exact-filter, Naive-prompt\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\"),\n",
    "        (\"Exact-filter, Simple-prompt\", \"/opt/gpudata/rrg-data-2/exp-findings/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Filter\": [\n",
    "        (\"No-filter\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Exact\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Partial\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-filter/Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Prompt\": [\n",
    "        (\"Naive\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"Simple\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Verbose\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_impression_METRICS.csv\"),\n",
    "        (\"Instruct\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-prompt/Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Model\": [\n",
    "        (\"Mistral-v3\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Mistral-v1\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"BioMistral\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-model/BioMistral-7B_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Label\": [\n",
    "        (\"True\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-label/Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Predicted\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-label/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Impression - Redundancy\": [\n",
    "        (\"No-filter, Naive-prompt\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"No-filter, Simple-prompt\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "        (\"Exact-filter, Naive-prompt\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\"),\n",
    "        (\"Exact-filter, Simple-prompt\", \"/opt/gpudata/rrg-data-2/exp-impression/exp-redundancy/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\"),\n",
    "    ],\n",
    "    \"Section\": [\n",
    "        (\"Both\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_both_METRICS.csv\"),\n",
    "        (\"Findings-Intersect\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings-intersect_METRICS.csv\"),\n",
    "        (\"Impression-Intersect\", \"/opt/gpudata/rrg-data-2/exp-section/Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression-intersect_METRICS.csv\"),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check duplicate runs are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(list)\n",
    "for g, ts in experiments.items():\n",
    "    for _, t in ts:\n",
    "        base = os.path.basename(t)\n",
    "        count[base].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(l) for l in count.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = {k: v for k, v in count.items() if len(v) > 1}\n",
    "print(len(dupes))\n",
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, runs in dupes.items():\n",
    "    group_dfs = []\n",
    "    for run in runs:\n",
    "        df = pd.read_csv(run)\n",
    "        group_dfs.append(df)\n",
    "    ref = group_dfs[0]\n",
    "    for df in group_dfs[1:]:\n",
    "        assert np.isclose(ref, df).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map colors to experiments\n",
    "list(count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette(palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\n",
    "    cmap[0]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[1]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_partial_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[4]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_both_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[2]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_naive_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[3]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_verbose_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[5]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_pred-label_instruct_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[6]: [\n",
    "        \"Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.1_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[7]: [\n",
    "        \"BioMistral-7B_exact_pred-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"BioMistral-7B_exact_pred-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[8]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_exact_true-label_simple_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[9]: [\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_findings_METRICS.csv\",\n",
    "        \"Mistral-7B-Instruct-v0.3_no-filter_pred-label_naive_top-5_impression_METRICS.csv\",\n",
    "    ],\n",
    "    cmap[10]: [\"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_findings-intersect_METRICS.csv\"],\n",
    "    cmap[11]: [\"Mistral-7B-Instruct-v0.3_exact_pred-label_simple_top-5_impression-intersect_METRICS.csv\"],\n",
    "}\n",
    "colors = {v: k for k, vs in temp.items() for v in vs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"bleu4\", \"rougeL\", \"bertscore\", \"f1radgraph\", \"f1chexbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, runs in experiments.items():\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    print(group)\n",
    "    group_results = []\n",
    "    for name, run in experiments[group]:\n",
    "        results = pd.read_csv(run).melt(id_vars=\"study_id\", var_name=\"metric\")\n",
    "        results[group] = name\n",
    "        group_results.append(results)\n",
    "    df = pd.concat(group_results, ignore_index=True)\n",
    "    x = \"metric\"\n",
    "    y = \"value\"\n",
    "    hue = group\n",
    "    hue_order = [n for n, _ in experiments[group]]\n",
    "    palette = [colors[os.path.basename(fp)] for _, fp in experiments[group]]\n",
    "    order = metrics\n",
    "    pairs = [\n",
    "        ((metric, n1), (metric, n2))\n",
    "        for metric in metrics\n",
    "        for i, n1 in enumerate(hue_order)\n",
    "        for n2 in hue_order[i+1:]\n",
    "    ]\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    sns.boxplot(\n",
    "        df,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        order=order,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        fliersize=0.1,\n",
    "        showmeans=True,\n",
    "        meanprops={\n",
    "            \"markersize\": 5,\n",
    "            \"markeredgecolor\": \"black\",\n",
    "            \"marker\": \"+\",\n",
    "            # \"marker\": \"P\",\n",
    "            # \"markerfacecolor\": \"black\",\n",
    "            # \"markeredgecolor\": \"darkgray\",\n",
    "            # \"markeredgewidth\": 1,\n",
    "        },\n",
    "    )\n",
    "    annot = Annotator(\n",
    "        ax,\n",
    "        pairs,\n",
    "        data=df,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        order=order,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        palette=palette,\n",
    "    )\n",
    "    # test = \"t-test_paired\" if group not in [\"Section\", \"Section-true\"] else \"t-test_ind\"\n",
    "    test = \"t-test_paired\"\n",
    "    annot.configure(\n",
    "        test=test,\n",
    "        comparisons_correction=\"Bonferroni\",\n",
    "        hide_non_significant=True,\n",
    "        loc=\"outside\",\n",
    "    )\n",
    "    annot.apply_test().annotate()\n",
    "    ax.set_ylim([-0.05, 1.65])\n",
    "    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.grid(which=\"major\", axis=\"y\")\n",
    "    ax.set_title(group)\n",
    "    legend = ax.legend(title=None, loc=\"upper left\")\n",
    "    legend.remove()\n",
    "    fig.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"figs/pngs/{group}.png\", dpi=300)\n",
    "    fig.savefig(f\"figs/pdfs/{group}.pdf\")\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(3, 1))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax2.legend(handles, labels, loc=\"center\")\n",
    "    ax2.axis(\"off\")\n",
    "    fig2.savefig(f\"figs/pngs/legends/{group}-legend.png\", dpi=300)\n",
    "    fig2.savefig(f\"figs/pdfs/legends/{group}-legend.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
