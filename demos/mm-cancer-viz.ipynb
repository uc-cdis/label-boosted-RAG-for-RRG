{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# TCGA Cancer Embedding Visualization Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Pull Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace this entire cell with getting the embeddings from the API\n",
    "# !wget \"https://uchicago.box.com/shared/static/k8z0kip2pej2v62pwgymdm45gt7dq0yw.h5\" -O \"data/hist.h5\"\n",
    "# !wget \"https://uchicago.box.com/shared/static/hr82b5c9g3h4y8c7avrnbgvhgdcoetld.h5\" -O \"data/expr.h5\"\n",
    "# !wget \"https://uchicago.box.com/shared/static/liwt3vlvdpmbfsa21wqboshh9nv6enm2.h5\" -O \"data/summ.h5\"\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "expr_file = \"with-all-data/data/expr.h5\" # BulkRNABert\n",
    "hist_file = \"with-all-data/data/hist.h5\" # UNI2\n",
    "text_file = \"with-all-data/data/summ.h5\" # BioMistral - Summarized\n",
    "\n",
    "expr_embs = dict()\n",
    "hist_embs = dict()\n",
    "text_embs = dict()\n",
    "\n",
    "for fpath, embs, do_upper in tqdm([\n",
    "    (expr_file, expr_embs, False),\n",
    "    (hist_file, hist_embs, False),\n",
    "    (text_file, text_embs, True),\n",
    "]):\n",
    "    with h5py.File(fpath, \"r\") as h5:\n",
    "        for case_id in h5.keys():\n",
    "            for sample_fname in h5[case_id].keys():\n",
    "                emb_key = sample_fname\n",
    "                if do_upper:\n",
    "                    emb_key = emb_key.upper()\n",
    "                embs[emb_key] = h5[case_id][sample_fname][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Pull and Join Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from jsonrpcclient import request, parse_json, Error\n",
    "\n",
    "# helper to parse the SSE-formatted response from the MCP server\n",
    "def parse_sse(response):\n",
    "    x = parse_json(response.text.split(\"\\n\", 1)[1].replace(\"data: \", \"\", 1))\n",
    "    if isinstance(x, Error):\n",
    "        raise ValueError(x.message)\n",
    "    return x.result\n",
    "\n",
    "# helper to use the MCP tool to construct a GDC cohort filter\n",
    "def get_cohort_filter(query: str) -> str:\n",
    "    return parse_sse(requests.post(\n",
    "        \"https://apps.m3aicommons.org/gdc-cohort-copilot/gradio_api/mcp/\",\n",
    "        json=request(\n",
    "            method=\"tools/call\",\n",
    "            params={\"name\": \"generate_filter\", \"arguments\": {\"query\": query}},\n",
    "        ),\n",
    "        headers={\"Accept\": \"application/json, text/event-stream\"},\n",
    "    ))[\"content\"][0][\"text\"]\n",
    "\n",
    "# helper to convert GDC request to file mapping\n",
    "def get_file_mapping(cohort_filter):\n",
    "    df = pd.read_csv(StringIO(requests.get(\n",
    "        \"https://api.gdc.cancer.gov/files\",\n",
    "        params={\n",
    "            \"filters\": cohort_filter, \"format\": \"TSV\", \"size\": str(100_000),\n",
    "            \"fields\": \",\".join([\"file_name\", \"cases.submitter_id\"]),                \n",
    "        },\n",
    "    ).text), sep=\"\\t\")\n",
    "    df = df[[\"cases.0.submitter_id\", \"file_name\"]]\n",
    "    df = df.rename(columns={\"cases.0.submitter_id\": \"case_id\"})\n",
    "    df[\"file_name\"] = df[\"file_name\"].str.replace(\".svs\", \"\").str.replace(\".rna_seq.augmented_star_gene_counts.tsv\", \"\").str.replace(\".PDF\", \"\")\n",
    "    return df.set_index(\"case_id\")[\"file_name\"]\n",
    "\n",
    "# Construct some cohort filters, you can print these to see what they look like!\n",
    "hist_filter = get_cohort_filter(\"TCGA samples with diagnostic slide svs files\")\n",
    "expr_filter = get_cohort_filter(\"TCGA samples with RNA-sequences gene expression quantification data as tsv files\")\n",
    "text_filter = get_cohort_filter(\"TCGA samples with pathology report pdf files\")\n",
    "\n",
    "# Query the API using the filters to get a mapping of case ID --> filename (from the embedding service)\n",
    "hist_mapping = get_file_mapping(hist_filter)\n",
    "expr_mapping = get_file_mapping(expr_filter)\n",
    "text_mapping = get_file_mapping(text_filter)\n",
    "\n",
    "# Get clinical metadata, this is standard code to pull data from the GDC\n",
    "# (though we use an extra call to the GDC Cohort Copilot for fun)\n",
    "response = requests.get(\n",
    "    \"https://api.gdc.cancer.gov/cases\",\n",
    "    params={\n",
    "        \"filters\": get_cohort_filter(\"samples from TCGA\"), \"format\": \"JSON\", \"size\": str(100_000),\n",
    "        \"fields\": \",\".join(\n",
    "            [\n",
    "                \"project.project_id\",\n",
    "                \"submitter_id\",\n",
    "                \"diagnoses.age_at_diagnosis\",\n",
    "                \"diagnoses.diagnosis_is_primary_disease\",\n",
    "                \"diagnoses.days_to_last_follow_up\",\n",
    "                \"demographic.days_to_death\",\n",
    "                \"demographic.vital_status\",\n",
    "                \"demographic.ethnicity\",\n",
    "                \"demographic.gender\",\n",
    "                \"demographic.race\",\n",
    "            ]\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "temp = json.loads(response.content)\n",
    "\n",
    "data = []\n",
    "for sample in temp[\"data\"][\"hits\"]:\n",
    "    if \"diagnoses\" not in sample:\n",
    "        continue\n",
    "    for diagnosis in sample[\"diagnoses\"]:\n",
    "        if \"diagnosis_is_primary_disease\" in diagnosis and diagnosis[\"diagnosis_is_primary_disease\"]:\n",
    "            break\n",
    "    else:\n",
    "        # no primary disease, skip\n",
    "        continue\n",
    "    if \"days_to_last_follow_up\" not in diagnosis:\n",
    "        # primary diagnosis does not have f/u\n",
    "        continue\n",
    "    data.append({\n",
    "        \"project_id\": sample[\"project\"][\"project_id\"],\n",
    "        \"case_id\": sample[\"submitter_id\"],\n",
    "        \"age_at_diagnosis\": diagnosis[\"age_at_diagnosis\"],\n",
    "        \"days_to_last_fu\": diagnosis[\"days_to_last_follow_up\"],\n",
    "        \"sex\": sample[\"demographic\"][\"gender\"],\n",
    "        \"race\": sample[\"demographic\"][\"race\"],\n",
    "        \"ethnicity\": sample[\"demographic\"][\"ethnicity\"],\n",
    "        \"vital_status\": sample[\"demographic\"][\"vital_status\"],\n",
    "    })\n",
    "\n",
    "case_ids = ( # case IDs that have all 3 embedding modalities\n",
    "    set(expr_mapping[expr_mapping.isin(expr_embs)].index) &\n",
    "    set(hist_mapping[hist_mapping.isin(hist_embs)].index) &\n",
    "    set(text_mapping[text_mapping.isin(text_embs)].index)\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[\n",
    "    df[\"case_id\"].isin(case_ids)\n",
    "    & df[\"vital_status\"].isin({\"Alive\", \"Dead\"})\n",
    "    & df[\"age_at_diagnosis\"].notna()\n",
    "    & df[\"days_to_last_fu\"].notna()\n",
    "    & (df[\"days_to_last_fu\"] >= 0)\n",
    "]\n",
    "df[\"age_at_diagnosis\"] /= 365.24 # convert age to years\n",
    "df[\"age_binned\"] = pd.cut(df[\"age_at_diagnosis\"], bins=np.arange(0, 101, 20))\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "expr_X = []\n",
    "hist_X = []\n",
    "text_X = []\n",
    "for _, row in df.iterrows():\n",
    "    case_id = row[\"case_id\"]\n",
    "    for embs, mapping, X in [\n",
    "        (expr_embs, expr_mapping, expr_X),\n",
    "        (hist_embs, hist_mapping, hist_X),\n",
    "        (text_embs, text_mapping, text_X),\n",
    "    ]:\n",
    "        fnames = mapping.loc[case_id]\n",
    "        if isinstance(fnames, str):\n",
    "            emb = embs[fnames] # fname is guaranteed to be in embeddings\n",
    "        else:\n",
    "            # at least one fname will be in embs\n",
    "            emb = np.mean([embs[f] for f in fnames if f in embs], axis=0)\n",
    "        X.append(emb)\n",
    "expr_X = np.asarray(expr_X)\n",
    "hist_X = np.asarray(hist_X)\n",
    "text_X = np.asarray(text_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scale_raw\", StandardScaler()),\n",
    "        (\"pca_reduce\", PCA(32, random_state=42)), # reduce dimensionality so UMAP runs faster\n",
    "        (\"scale_pca\", StandardScaler()), # normalize PCA output\n",
    "    ],\n",
    ")\n",
    "\n",
    "modality_map = {\n",
    "    \"expr\": clone(pipe).fit_transform(expr_X),\n",
    "    \"hist\": clone(pipe).fit_transform(hist_X),\n",
    "    \"text\": clone(pipe).fit_transform(text_X),\n",
    "}\n",
    "\n",
    "output_types = {\n",
    "    \"project_id\": \"cat\",\n",
    "    \"age_binned\": \"cat\",\n",
    "    \"sex\": \"cat\",\n",
    "    \"race\": \"cat\",\n",
    "    \"ethnicity\": \"cat\",\n",
    "    \"vital_status\": \"cat\",\n",
    "    \"age_at_diagnosis\": \"cont\",\n",
    "    \"days_to_last_fu\": \"cont\",\n",
    "}\n",
    "\n",
    "inputs = list(modality_map.keys())\n",
    "cat_outputs = [k for k, v in output_types.items() if v == \"cat\"]\n",
    "cont_outputs = [k for k, v in output_types.items() if v == \"cont\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Visualization Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import Checkbox, HBox, VBox, RadioButtons, Output, Label, Layout, HTML, interactive_output\n",
    "\n",
    "controls = {\n",
    "    name: Checkbox(value=i==0, description=name, indent=False)\n",
    "    for i, name in enumerate(inputs)\n",
    "}\n",
    "\n",
    "controls[\"color_selector\"] = RadioButtons(\n",
    "    options=cat_outputs + cont_outputs,\n",
    "    value=\"project_id\",\n",
    "    description=\"Color by:\",\n",
    ")\n",
    "\n",
    "output_plot = Output()\n",
    "\n",
    "spinner_html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; width: 100%; height: 500px;\">\n",
    "    <div class=\"loader\"></div>\n",
    "</div>\n",
    "\n",
    "<style>\n",
    ".loader {\n",
    "  border: 6px solid #f3f3f3;\n",
    "  border-top: 6px solid #3498db;\n",
    "  border-radius: 50%;\n",
    "  width: 30px;\n",
    "  height: 30px;\n",
    "  animation: spin 1s linear infinite;\n",
    "}\n",
    "\n",
    "@keyframes spin {\n",
    "  0% { transform: rotate(0deg); }\n",
    "  100% { transform: rotate(360deg); }\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "cached_modalities = dict()\n",
    "\n",
    "def update(color_selector, **modality_selections):\n",
    "    with output_plot:\n",
    "        output_plot.clear_output(wait=False)\n",
    "        display(HTML(spinner_html))\n",
    "        output_plot.clear_output(wait=True)\n",
    "\n",
    "        modalities = [name for name, checked in modality_selections.items() if checked]\n",
    "        modalities = sorted(modalities)\n",
    "        modalities_str = \", \".join(modalities)\n",
    "\n",
    "        if modalities_str == \"\":\n",
    "            print(\"Please select at least 1 modality\")\n",
    "            return\n",
    "\n",
    "        if modalities_str not in cached_modalities:\n",
    "            X = np.concatenate([modality_map[modality] for modality in modalities], axis=1)\n",
    "            cached_modalities[modalities_str] = UMAP(n_neighbors=30, n_jobs=4).fit_transform(X)\n",
    "        reduced = cached_modalities[modalities_str]\n",
    "\n",
    "        df[\"UMAP-1\"] = reduced[:, 0]\n",
    "        df[\"UMAP-2\"] = reduced[:, 1]\n",
    "        hue_col = color_selector.replace(\"_\", \" \").title().replace(\"Fu\", \"FU\").replace(\"Id\", \"ID\").replace(\"At\", \"at\")\n",
    "        output_type = output_types[color_selector]\n",
    "        kwargs = dict()\n",
    "        if output_type == \"cont\":\n",
    "            kwargs[\"palette\"] = \"viridis\"\n",
    "        df[hue_col] = pd.Categorical(df[color_selector]) if output_type == \"cat\" else df[color_selector]\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 7))\n",
    "        sns.scatterplot(df, x=\"UMAP-1\" ,y=\"UMAP-2\", hue=hue_col, s=10, ax=ax, **kwargs)\n",
    "        sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1), markerscale=2)\n",
    "        plt.show()\n",
    "\n",
    "interactive = interactive_output(update, controls)\n",
    "checkbox_column = VBox([Label(\"Embedding Modality:\")] + list(controls.values()), layout=Layout(width=\"150px\"))\n",
    "ui = HBox([checkbox_column, VBox([output_plot], layout=Layout(width=\"1000px\"))])\n",
    "display(ui, interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
